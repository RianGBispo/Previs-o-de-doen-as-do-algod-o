{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo  deteccao de doencas do algodao](CottonDiseasePrediction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de Doenças em Algodão\n",
    "\n",
    "Bem-vindo ao meu projeto de detecção de doenças em plantações de algodão! Neste notebook, exploraremos uma abordagem baseada em visão computacional e aprendizado de máquina para identificar e classificar se a imagem pertence ou não à classe doente.\n",
    "\n",
    "### Objetivo do Projeto\n",
    "\n",
    "O principal objetivo deste projeto é desenvolver um sistema de detecção simples e preciso que possa ajudar agricultores a identificar rapidamente problemas de saúde em suas plantações de algodão. A detecção precoce de doenças é crucial para a implementação de medidas preventivas e o controle efetivo, contribuindo para uma produção saudável e sustentável.\n",
    "\n",
    "### Metodologia\n",
    "\n",
    "Utilizaremos técnicas avançadas de processamento de imagens e machine learning, mais especificamente CNN, para treinar um modelo capaz de reconhecer padrões associados a diferentes doenças em folhas de algodão. Este projeto se concentrará em técnicas de classificação para implementação e avaliação do modelo.\n",
    "\n",
    "### Conjunto de Dados\n",
    "\n",
    "Para alcançar nossos objetivos, utilizaremos um conjunto de dados abrangente, contendo imagens rotuladas de folhas de algodão saudáveis e afetadas por diversas doenças.\n",
    "\n",
    "### Estrutura do Notebook\n",
    "\n",
    "1. Bibliotecas\n",
    "2. Treinamento e DataLoader\n",
    "3. Construindo a CNN\n",
    "4. Resumo\n",
    "5. Treinamento da CNN\n",
    "6. Teste\n",
    "7. Conclusão\n",
    "\n",
    "Vamos começar!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando o Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 10 15:02:45 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.12                 Driver Version: 546.12       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   56C    P8               7W /  45W |     69MiB /  6144MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m      4\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU não disponível. Usando CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8551858905635952306\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Treinamento e DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando gerador de imagens para aumentação de dados.\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,           # Normalização dos valores dos pixels para intervalo entre 0 e 1.\n",
    "                                   shear_range = 0.2,        # Cisalhamento aleatório para criar uma distorção semelhante a uma tesoura.\n",
    "                                   zoom_range = 0.2,          # Zoom aleatório para adicionar variação à escala.\n",
    "                                   horizontal_flip = True)   # Inversão horizontal aleatória para adicionar variação refletindo a imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1951 images belonging to 4 classes.\n",
      "Found 106 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Configurando o conjunto de treinamento usando o gerador de imagens para aumentação de dados.\n",
    "training_set = train_datagen.flow_from_directory('Cotton Disease/train',\n",
    "                                                 target_size=(64, 64),   # Tamanho desejado para as imagens (64x64 pixels).\n",
    "                                                 batch_size=32,          # Tamanho do lote de imagens utilizado durante o treinamento.\n",
    "                                                 class_mode='categorical')  # Modo de classificação categórica para problemas de classificação multiclasse.\n",
    "\n",
    "# Configurando o conjunto de teste usando um gerador de imagens sem aumentação de dados.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Apenas normalização para o conjunto de teste.\n",
    "test_set = test_datagen.flow_from_directory('Cotton Disease/test',\n",
    "                                            target_size=(64, 64),   # Tamanho desejado para as imagens (64x64 pixels).\n",
    "                                            batch_size=32,          # Tamanho do lote de imagens utilizado durante a avaliação.\n",
    "                                            class_mode='categorical')  # Modo de classificação categórica para problemas de classificação multiclasse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo a Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine que estamos treinando um \"cérebro artificial\", ou rede neural, para reconhecer diferentes tipos de imagens, como gatos, cachorros, carros, ou doenças no algodão, como é o nosso caso.\n",
    "\n",
    "#### Primeira Etapa - Reconhecimento de Formas:\n",
    "\n",
    "No início, o cérebro aprende a reconhecer formas básicas nas imagens, como bordas, curvas, ou padrões simples. Isso é feito através de uma fase chamada \"convolução\", onde o cérebro olha para pequenas partes da imagem de cada vez.\n",
    "\n",
    "Em seguida, ele dá uma olhada mais ampla para entender as características mais importantes, como a forma geral, usando uma fase chamada \"agrupamento\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Iniciando a CNN\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cnn \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Passo 1 - Convolução\u001b[39;00m\n\u001b[0;32m      5\u001b[0m cnn\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m      6\u001b[0m                                padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m                                kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      8\u001b[0m                                activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m                                input_shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Iniciando a CNN\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# Passo 1 - Convolução\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,\n",
    "                               padding=\"same\",\n",
    "                               kernel_size=3,\n",
    "                               activation='relu',\n",
    "                               input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segunda Etapa - Compreensão Avançada:\n",
    "\n",
    "Depois de aprender essas características básicas, o cérebro aprimora sua compreensão, olhando para partes maiores e mais complexas das imagens. Isso é feito adicionando outra camada de \"convolução\" e \"agrupamento\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2 - Agrupamento\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Adicionando uma seguinda camada convolucvional\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, padding='same', kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Próximo Passo - Pensamento Abstrato:\n",
    "\n",
    "Agora, o cérebro precisa pensar de maneira mais abstrata. Ele \"esmaga\" as informações aprendidas até agora para torná-las mais fáceis de entender, e isso é chamado de \"achatamento\".\n",
    "\n",
    "Em seguida, ele conecta todas essas informações da maneira que o cérebro humano faz, para entender padrões mais complexos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 3 - Achatamento\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Passo 4 - Conexão completa\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decisões Finais - Qual é a Imagem?:\n",
    "\n",
    "Finalmente, o cérebro faz as decisões finais. Com base em tudo o que aprendeu, decide se a imagem é de uma planta doente ou não.\n",
    "\n",
    "Ele atribui probabilidades a cada opção, o que significa que ele pode não ter certeza absoluta, mas faz a melhor suposição possível.\n",
    "\n",
    "Em resumo, a Convolutional Neural Network (CNN) é como um cérebro artificial que aprende a reconhecer diferentes coisas em imagens, passo a passo, desde formas simples até padrões mais complexos, para tomar decisões sobre o que está vendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 5 - Camada de saída\n",
    "cnn.add(tf.keras.layers.Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 32, 32, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1059364 (4.04 MB)\n",
      "Trainable params: 1059364 (4.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando a CNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
